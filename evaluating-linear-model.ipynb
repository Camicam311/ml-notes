{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing\n",
    "- Steps:\n",
    "    1. Assume $H_0$, then null hypothesis.\n",
    "<br/><br/>\n",
    "    2. Check if data supports $H_0$ (fails to reject null hypothesis) or $H_1$ (rejects null hypothesis).\n",
    "        - If $H_0$, $\\beta_1 = 0$, (coefficients/parameters are zero) and 95% of Confidence Interval <strong>does not include</strong> zero.\n",
    "        - If $H_1$, $\\beta_1 \\not= 0$, (coefficients/parameters are not zero) and 95% of Confidence Interval <strong>includes</strong> zero.\n",
    "\n",
    "## p-value\n",
    "- Represents the probability that the coefficient is actually zero.\n",
    "<br/><br/>\n",
    "- If the 95% of CI (Confidence Interval) does not include zero:\n",
    "    - p < 0.05\n",
    "    - Reject $H_0$\n",
    "    - There is a relationship.\n",
    "<br/><br/>\n",
    "- If the 95% of CI (Confidence Interval) includes zero:\n",
    "    - p > 0.05\n",
    "    - Fail to reject $H_0$\n",
    "    - There is no relationship.\n",
    "\n",
    "## $R^2$: How well does the model fit data?\n",
    "- $R^2$ used to evaluate linear model.\n",
    "<br/><br/>\n",
    "- $R^2$ (Coef. of determination) is the proportion of variance explained.\n",
    "<br/><br/>\n",
    "- Mathematically:\n",
    "<br/><br/>\n",
    "    - $R^2 = 1 - \\frac{SS_{res}}{SS_{tot}}$ and $R^2 \\in [0,1]$\n",
    "<br/><br/>    \n",
    "    - where $SS_{res} = \\sum_i(y_i-f_i)^2 = \\sum_ie_i^2$ and $SS_{tot}=\\sum_i(y_i-\\bar y)^2$\n",
    "<br/><br/>\n",
    "    - and $\\bar y = \\frac{1}{n}\\sum y_i$ as the mean of the observed data\n",
    "<br/><br/>\n",
    "- Higher value of $R^2$ is better since it means that more variance is explained by the model.\n",
    "<br/><br/>\n",
    "- Threshold for a <strong>'good'</strong> $R^2$ depends on the domain, so the most useful tool is to compare different models.\n",
    "<br/><br/>\n",
    "- $R^2$ is susceptible to <strong>overfitting</strong> and thus there is no guarantee that a model with high $R^2$ value will generalize.\n",
    "<br/><br/>\n",
    "- <strong>Issue with $R^2$</strong>: R-squared will always increase as you add more features to the model, even if they are unrelated to the response. So selecting a model with the highest $R^2$ is not a reliable approach for choosing the best linear model.\n",
    "<br/><br/>\n",
    "- <strong>So how do we go around this issue?</strong>\n",
    "    - Adjusted $R^2$: penalizes model complexity, but it generally <strong>under-penalizes complexity</strong>.\n",
    "    - Train/test split or Cross validation: \n",
    "        - More reliable estimate of out-of-sample error (better for choosing which of the models will best <strong>generalize</strong> to out-of-sample data.\n",
    "\n",
    "## Residual Plots\n",
    "$$Residual = Observed - Predicted$$\n",
    "- Positive values for the residual (on the y-axis) mean the prediction was too low, and negative values mean the prediction was too high. 0 means that the guess was exactly correct.\n",
    "- Following are some examples of ideal residual plots:\n",
    "![img](assets/ideal-residual.png)\n",
    "![img](assets/ideal-residual1.png)\n",
    "![img](assets/ideal-residual2.png)\n",
    "![img](assets/ideal-residual3.png)\n",
    "- An ideal residual plot are:\n",
    "    - symmetrically distributed, tend to cluster around the center of the plot.\n",
    "    - clustered around the lower single digits of the y-axis (i.e. 0.5, 1.5 instead of 30 or 150).\n",
    "    - have no clear patterns.\n",
    "<br/><br/>\n",
    "- Following are some examples of bad residual plots:\n",
    "![img](assets/bad-residual.png)\n",
    "![img](assets/bad-residual1.png)\n",
    "![img](assets/bad-residual2.png)\n",
    "![img](assets/bad-residual3.png)\n",
    "- These plots are:\n",
    "    - not evenly distributed vertically, or have outliers, or have a clear shape.\n",
    "    - have clear pattern that is apparent.\n",
    "- So how much does this matter?\n",
    "    - <strong>“Essentially, all models are wrong, but some are useful”</strong> - George Box\n",
    "    - Performance and accuracy may be an issue if you are trying to publish your thesis in particle physics.\n",
    "    - If you are trying to run a quick dirty analysis, less than a perfect model might be good enough to answer whatever questions you have.\n",
    "    - Most of the time a descent model is better than none at all!\n",
    "<br/><br/>\n",
    "\n",
    "Source:\n",
    "- https://www.ritchieng.com/machine-learning-evaluate-linear-regression-model/\n",
    "- https://en.wikipedia.org/wiki/Coefficient_of_determination#Definitions\n",
    "- http://scott.fortmann-roe.com/docs/MeasuringError.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
